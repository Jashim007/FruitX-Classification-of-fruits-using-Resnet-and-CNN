{"cells":[{"metadata":{"_uuid":"36dfa86b-f472-48a7-b267-b60a532cb46d","_cell_guid":"1cb3f43a-3430-4fe1-9fbe-9af42d363da4","trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn.datasets import load_files\nimport numpy as np\n\ntrain_dir = '../input/fruits/Fruits_1/Training'\ntest_dir = '../input/fruits/Fruits_1/Test'\n\ndef load_dataset(path):\n    data = load_files(path)\n    files = np.array(data['filenames'])\n    targets = np.array(data['target'])\n    target_labels = np.array(data['target_names'])\n    return files,targets,target_labels\n    \nx_train, y_train,target_labels = load_dataset(train_dir)\nx_test, y_test,_ = load_dataset(test_dir)\nprint('Loading complete!')\n\nprint('Training set size : ' , x_train.shape[0])\nprint('Testing set size : ', x_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ce96b4f-5b98-4b4a-b095-4b16b52bd444","_cell_guid":"20abeb46-5fa8-477d-b35c-64d2773d7b45","trusted":true,"scrolled":true},"cell_type":"code","source":"target_labels","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c067c038-8b46-4574-9fba-d4ff01ecadee","_cell_guid":"1c1aba64-4772-4c58-9a43-ba0efb0b966c","trusted":true,"scrolled":true},"cell_type":"code","source":"no_of_classes = len(np.unique(y_train))\nno_of_classes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc3c4d10-40e9-4447-83e8-e913f598f557","_cell_guid":"34c9fa81-5b67-4914-8eea-6fbae8610fd3","trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48ac5815-501f-4421-bc1a-7713bc409566","_cell_guid":"a5014e04-69f3-4688-8fd9-cd3c7fc12a26","trusted":true},"cell_type":"code","source":"x_train","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c0fe219-d592-4f56-891b-19096c4e9bad","_cell_guid":"802a41f1-1adc-4743-b192-69a9d6897488","trusted":true,"scrolled":true},"cell_type":"code","source":"from keras.utils import np_utils\ny_train = np_utils.to_categorical(y_train,no_of_classes)\ny_test = np_utils.to_categorical(y_test,no_of_classes)\ny_train[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1c790df-ec29-4f92-aa70-016cd5606bb3","_cell_guid":"87c75d67-731b-4238-9f16-107aa0571512","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nimport keras\nimport numpy as np # linear algebra\nimport keras.backend as K \nimport time as ti \nimport cv2\nimport os\nimport glob # for including images\nimport scipy.io as sio\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\nfrom tensorflow.python.keras.layers import Conv2D, DepthwiseConv2D, MaxPooling2D, AveragePooling2D  \nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.optimizers import RMSprop, SGD, Adadelta, Adam \nfrom keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cdb114d3-0190-4cb7-93a4-e62d9eae54a6","_cell_guid":"0c3b4006-78af-4492-8a9b-969a922eef4a","trusted":true},"cell_type":"code","source":"len(x_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53661047-4d5a-4e03-98a6-8e76382727e9","_cell_guid":"270eef91-c526-4f8b-a7af-91aec88ead6e","trusted":true,"scrolled":true},"cell_type":"code","source":"x_test,x_valid =x_test[3500:],x_test[:3500]\ny_test,y_valid = y_test[3500:],y_test[:3500]\nprint('Vaildation X : ',x_valid.shape)\nprint('Vaildation y :',y_valid.shape)\nprint('Test X : ',x_test.shape)\nprint('Test y : ',y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee665f36-4686-4cdc-a9f9-085e9d1954ac","_cell_guid":"7e7cc9a9-25d5-4ae6-a5fa-956d1b82f1c6","trusted":true,"scrolled":true},"cell_type":"code","source":"from keras.preprocessing.image import array_to_img, img_to_array, load_img\n\ndef convert_image_to_array(files):\n    images_as_array=[]\n    for file in files:\n        # Convert to Numpy Array\n        images_as_array.append(img_to_array(load_img(file)))\n    return images_as_array\n\nx_train = np.array(convert_image_to_array(x_train))\nprint('Training set shape : ',x_train.shape)\n\nx_valid = np.array(convert_image_to_array(x_valid))\nprint('Validation set shape : ',x_valid.shape)\n\nx_test = np.array(convert_image_to_array(x_test))\nprint('Test set shape : ',x_test.shape)\n\nprint('1st training image shape ',x_train[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6a0451c-fbc7-4c51-8dd4-63eab77610b5","_cell_guid":"d70c4aaa-15b4-4e9d-b280-84bdd2d87e42","trusted":true,"scrolled":true},"cell_type":"code","source":"x_train/=255\nx_valid/=255\nx_test/=255","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5c9e255-3f90-4d6b-9b70-36b0cb659f19","_cell_guid":"f6463bcc-8003-4490-8715-10d2a76cc577","trusted":true},"cell_type":"code","source":"# model = Sequential()\n# nf1=20; nf2=30; nf3=10; \n# pad='same'\n    \n# # First conv layer\n# model.add(Conv2D(filters=nf1,padding=pad, kernel_size=(3,3),input_shape=(100,100,3), activation='relu',))\n# model.add(MaxPooling2D(pool_size=(4, 4),strides=(2,2),padding=pad))\n    \n# # Second conv layer\n# model.add(Conv2D(filters=nf2,padding=pad, kernel_size=(3,3), activation='relu',))\n# model.add(MaxPooling2D(pool_size=(4, 4),strides=(2,2),padding=pad))\n    \n# # Third conv layer \n# model.add(Conv2D(filters=nf3,padding=pad, kernel_size=(3,3), activation='relu',))\n# model.add(MaxPooling2D(pool_size=(4, 4),strides=(2,2),padding=pad))\n \n# model.add(GlobalAveragePooling2D())\n# # model.add(Flatten())\n    \n# # Output with 131 neurons ( 131 classes )\n# model.add(Dense(41, activation='softmax'))\n    \n# # model.compile(loss='categorical_crossentropy', \n# #               optimizer='adam',\n# #               metrics=['accuracy',recall])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcfa6123-6f4c-4260-b2f3-e238dd261d61","_cell_guid":"87ef6b25-6765-47e0-ad81-057902057d90","trusted":true,"scrolled":true},"cell_type":"code","source":"import tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.layers import Activation, Dense, Flatten, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import backend as K\nimport numpy as np\n\ntf.compat.v1.set_random_seed(\n    0\n)\nnp.random.seed(0)\n\nmodel=Sequential()\nmodel.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 256,kernel_size = 2,activation= 'relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(150))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(41,activation = 'softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b7a6ced-0c38-4dcb-89c4-b50fbeec798c","_cell_guid":"6e608f3c-8377-4480-b729-570df9d41ea5","trusted":true,"scrolled":true},"cell_type":"code","source":"def recall(y_true, y_pred):\n     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n     possible_positives= K.sum(K.round(K.clip(y_true, 0, 1)))\n     recall = true_positives / (possible_positives + K.epsilon())\n     return recall\n\ndef precision(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='nadam',\n              metrics=['accuracy',recall,precision])\nprint('Compiled!')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68765bef-00d2-4e93-939a-dc6800fa922d","_cell_guid":"00fdf6ef-b6fe-4fd4-9f8d-3c18a01bb217","trusted":true,"scrolled":true},"cell_type":"code","source":"from keras.models import Sequential\nimport tensorflow as tf\nimport numpy as np\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.layers import Activation, Dense, Flatten, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import backend as K\n# batch_size = 100\n# input_shape=(1001,100,3)\n# epochs=30\n\ntf.compat.v1.set_random_seed(0)\nnp.random.seed(0)\ncheckpointer = ModelCheckpoint(filepath = 'cnn_from_scratch_fruits.hdf5', verbose = 2, save_best_only = True,mode='max',monitor='val_accuracy')\n\n\ntrain_image_generator = ImageDataGenerator(rotation_range=45,width_shift_range=.15,height_shift_range=.15,horizontal_flip=True, zoom_range=0.3)\ntrain_data_gen = train_image_generator.flow(x_train,y_train)\n\n\n\n\n\n# history=model.fit(train_data_gen,\n#           steps_per_epoch=500, epochs=10,validation_data=(x_valid,y_valid),\n#         callbacks = [checkpointer],\n#                     verbose=2,shuffle=True)\n\nhistory=model.fit(train_data_gen,\n                       steps_per_epoch=500,\n                       epochs=10,\n                       verbose=1,\n                       validation_data=(x_valid,y_valid),\n                       callbacks=[checkpointer]\n                      )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbef67c5-a823-4746-b21f-ea44568d3af5","_cell_guid":"42c35cee-b204-4358-94fc-2029247d1dec","trusted":true,"scrolled":false},"cell_type":"code","source":"dict_idx_fruit = {idx: label for idx, label in enumerate(target_labels)}\nprint(dict_idx_fruit)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"615612a3-995c-4963-94ed-1bdfb4d8333a","_cell_guid":"1095a5b9-8a93-45a9-95a0-e3ba9f49dd80","trusted":true,"scrolled":false},"cell_type":"code","source":"num_categories = len(np.unique(y_train))\nnum_categories","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"990d8071-20bc-467b-9f6a-661338202437","_cell_guid":"50c7ff05-3fc7-45d7-a229-8d82faeaa4c3","trusted":true,"scrolled":true},"cell_type":"code","source":"model.load_weights('cnn_from_scratch_fruits.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6388e3a5-4cfb-469c-9263-7a18edec59b2","_cell_guid":"90ccc1f3-5410-4d1f-b19d-e311a2c0865f","trusted":true,"scrolled":true},"cell_type":"code","source":"# test_image_generator.flow(x_test,y_test)\nscore = model.evaluate(x_test,y_test)\nprint('\\n', 'Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae173f41-bc3e-4946-9954-4cea010e3074","_cell_guid":"66bebd5f-882c-4027-84cb-5d9907392618","trusted":true,"scrolled":true},"cell_type":"code","source":"preds=np.round(model.predict(x_test),0)\nprint(\"Rounded test_labels\",preds)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a86b0e4c-aa1b-4457-ab76-eeb4a8f82676","_cell_guid":"0f24a8e9-46f8-4829-8efe-509b8699006b","trusted":true,"scrolled":false},"cell_type":"code","source":"#Let's visualize the first 10 training images!\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize =(30,5))\nfor i in range(10):\n    ax = fig.add_subplot(2,5,i+1,xticks=[],yticks=[])\n    ax.imshow(np.squeeze(x_train[i]))\n# Yummy fruits ;)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96768997-d4cf-4971-9041-3649c0b9a291","_cell_guid":"f2b36b0e-4bf7-4ff1-acc9-f626fe8e1935","trusted":true,"scrolled":false},"cell_type":"code","source":"# Let's visualize test prediction.\n\ny_pred = model.predict(x_test)\n\n# plot a random sample of test images, their predicted labels, and ground truth\nfig = plt.figure(figsize=(16, 9))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = np.argmax(y_pred[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84271161-98c3-4b1e-b769-873c402f4f3e","_cell_guid":"2689c8d7-6eb9-4543-b1dd-52678848169d","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nplt.figure(figsize=(20,10))\n   \n # summarize history for accuracy  \n   \nplt.subplot(121)  \nplt.plot(history.history['accuracy'])  \nplt.plot(history.history['val_accuracy'],color='red')  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'validation'], loc='upper left')  \n   \n # summarize history for loss  \n   \nplt.subplot(122)  \nplt.plot(history.history['loss'])  \nplt.plot(history.history['val_loss'],color='red')  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'validation'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2569fda-ee02-43d7-a4de-5f56419fa883","_cell_guid":"338a18f2-1ea2-4658-92ab-00757f4e8fe9","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"446ac637-f2f0-4866-8cff-c099b78444ea","_cell_guid":"c2b95dfa-65e2-4f88-a308-06868c4e0adc","trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\ncm=confusion_matrix(\n    y_test.argmax(axis=1), preds.argmax(axis=1))\ncm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e51ede7-88a5-47de-a43b-628e1e397a30","_cell_guid":"bcbc36da-8c29-4c54-bf7b-d5ebab33947e","trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nclassification=metrics.classification_report(y_test,preds)\nprint(classification)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54d3173a-ee46-43b8-ae63-8b74dec73901","_cell_guid":"cdcbca51-3a09-4855-b964-d2396a11efa4","trusted":true,"scrolled":true},"cell_type":"code","source":"cm.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e42077fa-b07b-4349-86d0-ca2c893f18aa","_cell_guid":"8d319f79-baaa-4a55-ad0a-309d3e7b43a6","trusted":true,"scrolled":false},"cell_type":"code","source":"\n\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf_cm = pd.DataFrame(cm, index = [i for i in range(41)],\n                  columns = [i for i in range(41)])\nplt.figure(figsize = (35,35))\nsn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61fb7f14-5b59-4942-995d-8b4758562b1d","_cell_guid":"2070a10c-5ad3-4c85-8e6e-bb2eae447676","trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e821db11-d05d-4f12-8fd4-63cbd0ce9dc4","_cell_guid":"24d5ecf2-602b-430f-a5f3-9b50e8a097db","trusted":true,"scrolled":true},"cell_type":"code","source":"# for layer in model.layers:\n#     if 'conv2d' in layer.name:\n#         weights, bias= layer.get_weights()\n#         print(layer.name, filters.shape)\n        \n#         #normalize filter values between  0 and 1 for visualization\n#         f_min, f_max = weights.min(), weights.max()\n#         filters = (weights - f_min) / (f_max - f_min)  \n#         print(filters.shape[3])\n#         filter_cnt=1\n        \n#         #plotting all the filters\n#         for i in range(filters.shape[5]):\n#             #get the filters\n#             filt=filters[:,:,:, i]\n#             #plotting each of the channel, color image RGB channels\n#             for j in range(filters.shape[0]):\n#                 ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\n#                 ax.set_xticks([])\n#                 ax.set_yticks([])\n#                 plt.imshow(filt[:,:, j])\n#                 filter_cnt+=1\n#         plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04ba5d63-a8d5-4c59-a84f-b642a2a6ffc8","_cell_guid":"5dbb17a0-9143-484c-a13c-ecbedcdaa148","trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn import metrics\nmetrics.roc_auc_score(y_test, preds,multi_class=\"ovr\",average='weighted')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca845e47-3633-414e-b0ea-d05de5da56d6","_cell_guid":"9c09bde1-7ec5-49ba-8a38-639931887433","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}